#!/bin/bash

# å…¨åŠŸèƒ½ç»¼åˆæµ‹è¯•è„šæœ¬
# æµ‹è¯•æ‰€æœ‰é«˜çº§åŠŸèƒ½ï¼šJOINæ“ä½œã€å¤šæ•°æ®æºã€è¾¹ç¼˜æƒ…å†µç­‰

API_BASE="http://localhost:8000"

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

log_info() { echo -e "${BLUE}â„¹ï¸  $1${NC}"; }
log_success() { echo -e "${GREEN}âœ… $1${NC}"; }
log_warning() { echo -e "${YELLOW}âš ï¸  $1${NC}"; }
log_error() { echo -e "${RED}âŒ $1${NC}"; }

test_api() {
    local description=$1
    local method=$2
    local endpoint=$3
    local data=$4
    
    echo ""
    log_info "æµ‹è¯•: $description"
    
    if [ "$method" = "POST" ]; then
        response=$(curl -s -X POST -H "Content-Type: application/json" -d "$data" "$API_BASE$endpoint")
    else
        response=$(curl -s "$API_BASE$endpoint")
    fi
    
    if echo "$response" | grep -q '"success":true\|"status":"healthy"'; then
        log_success "$description - æˆåŠŸ"
        echo "å“åº”: $(echo "$response" | head -c 200)..."
    else
        log_error "$description - å¤±è´¥"
        echo "é”™è¯¯: $response"
    fi
    
    return 0
}

echo "ğŸš€ DataQuery Pro å…¨åŠŸèƒ½ç»¼åˆæµ‹è¯•"
echo "======================================="

# ==========================================
# ç¬¬ä¸€éƒ¨åˆ†ï¼šå‡†å¤‡æµ‹è¯•æ•°æ®
# ==========================================
echo ""
echo "ğŸ“‹ ç¬¬ä¸€éƒ¨åˆ†ï¼šå‡†å¤‡æµ‹è¯•æ•°æ®"
echo "========================"

# åˆ›å»ºå‘˜å·¥è¡¨
log_info "åˆ›å»ºå‘˜å·¥è¡¨ (employees.csv)"
cat > employees.csv << 'EOF'
emp_id,name,age,department_id,salary,hire_date
1,å¼ ä¸‰,28,1,8000,2020-01-15
2,æå››,32,2,12000,2019-03-20
3,ç‹äº”,25,1,7500,2021-06-10
4,èµµå…­,35,3,15000,2018-11-05
5,é’±ä¸ƒ,29,2,9500,2020-08-12
6,å­™å…«,31,3,13000,2019-07-18
7,å‘¨ä¹,26,1,7800,2021-02-28
8,å´å,33,4,11000,2020-05-03
EOF

# åˆ›å»ºéƒ¨é—¨è¡¨
log_info "åˆ›å»ºéƒ¨é—¨è¡¨ (departments.csv)"
cat > departments.csv << 'EOF'
dept_id,dept_name,manager_id,budget
1,æŠ€æœ¯éƒ¨,4,500000
2,é”€å”®éƒ¨,2,300000
3,å¸‚åœºéƒ¨,6,250000
4,äººäº‹éƒ¨,8,150000
5,è´¢åŠ¡éƒ¨,,200000
EOF

# åˆ›å»ºé¡¹ç›®è¡¨
log_info "åˆ›å»ºé¡¹ç›®è¡¨ (projects.csv)"
cat > projects.csv << 'EOF'
project_id,project_name,department_id,budget,start_date,status
101,ç”µå•†å¹³å°,1,800000,2021-01-01,è¿›è¡Œä¸­
102,è¥é”€æ´»åŠ¨,2,150000,2021-03-15,å·²å®Œæˆ
103,å“ç‰Œæ¨å¹¿,3,200000,2021-02-01,è¿›è¡Œä¸­
104,äººæ‰æ‹›è˜,4,80000,2021-04-01,å·²å®Œæˆ
105,è´¢åŠ¡ç³»ç»Ÿ,1,600000,2020-12-01,è¿›è¡Œä¸­
106,å®¢æˆ·ç®¡ç†,2,300000,2021-05-01,è®¡åˆ’ä¸­
EOF

# åˆ›å»ºé”€å”®æ•°æ®è¡¨
log_info "åˆ›å»ºé”€å”®æ•°æ®è¡¨ (sales.csv)"
cat > sales.csv << 'EOF'
sale_id,emp_id,product,amount,sale_date,region
1001,2,äº§å“A,50000,2021-01-15,ååŒ—
1002,2,äº§å“B,30000,2021-01-20,ååŒ—
1003,5,äº§å“A,45000,2021-02-10,åä¸œ
1004,2,äº§å“C,60000,2021-02-15,ååŒ—
1005,5,äº§å“B,35000,2021-03-05,åä¸œ
1006,2,äº§å“A,55000,2021-03-20,ååŒ—
1007,5,äº§å“C,40000,2021-04-12,åä¸œ
EOF

# ä¸Šä¼ æ‰€æœ‰æµ‹è¯•æ–‡ä»¶
for file in employees.csv departments.csv projects.csv sales.csv; do
    log_info "ä¸Šä¼ æ–‡ä»¶: $file"
    upload_result=$(curl -s -X POST -F "file=@$file" "$API_BASE/api/upload")
    if echo "$upload_result" | grep -q "success"; then
        log_success "æ–‡ä»¶ $file ä¸Šä¼ æˆåŠŸ"
    else
        log_error "æ–‡ä»¶ $file ä¸Šä¼ å¤±è´¥: $upload_result"
    fi
done

# ==========================================
# ç¬¬äºŒéƒ¨åˆ†ï¼šåŸºç¡€å•è¡¨æŸ¥è¯¢æµ‹è¯•
# ==========================================
echo ""
echo "ğŸ“Š ç¬¬äºŒéƒ¨åˆ†ï¼šåŸºç¡€å•è¡¨æŸ¥è¯¢æµ‹è¯•"
echo "=========================="

# åŸºç¡€æŸ¥è¯¢
test_api "åŸºç¡€SELECTæŸ¥è¯¢" "POST" "/api/execute_simple_sql" \
'{"sql": "SELECT * FROM employees LIMIT 5", "filename": "employees.csv"}'

# æ¡ä»¶æŸ¥è¯¢
test_api "æ¡ä»¶WHEREæŸ¥è¯¢" "POST" "/api/execute_simple_sql" \
'{"sql": "SELECT name, age, salary FROM employees WHERE age > 30", "filename": "employees.csv"}'

# æ’åºæŸ¥è¯¢
test_api "ORDER BYæ’åºæŸ¥è¯¢" "POST" "/api/execute_simple_sql" \
'{"sql": "SELECT name, salary FROM employees ORDER BY salary DESC", "filename": "employees.csv"}'

# èšåˆæŸ¥è¯¢
test_api "èšåˆGROUP BYæŸ¥è¯¢" "POST" "/api/execute_simple_sql" \
'{"sql": "SELECT department_id, COUNT(*) as emp_count, AVG(salary) as avg_salary FROM employees GROUP BY department_id", "filename": "employees.csv"}'

# ç»Ÿè®¡æŸ¥è¯¢
test_api "ç»Ÿè®¡å‡½æ•°æŸ¥è¯¢" "POST" "/api/execute_simple_sql" \
'{"sql": "SELECT COUNT(*) as total, MIN(salary) as min_sal, MAX(salary) as max_sal, AVG(age) as avg_age FROM employees", "filename": "employees.csv"}'

# ==========================================
# ç¬¬ä¸‰éƒ¨åˆ†ï¼šJOINæ“ä½œæµ‹è¯•
# ==========================================
echo ""
echo "ğŸ”— ç¬¬ä¸‰éƒ¨åˆ†ï¼šJOINæ“ä½œæµ‹è¯•"
echo "======================"

# éœ€è¦å…ˆæ³¨å†Œå¤šä¸ªè¡¨åˆ°DuckDBï¼Œåˆ›å»ºå¤šè¡¨æŸ¥è¯¢API
log_info "å‡†å¤‡å¤šè¡¨JOINæŸ¥è¯¢æµ‹è¯•"

# INNER JOINæµ‹è¯•
test_api "INNER JOINæŸ¥è¯¢" "POST" "/api/multi_table_query" \
'{
  "files": ["employees.csv", "departments.csv"],
  "sql": "SELECT e.name, e.salary, d.dept_name FROM employees e INNER JOIN departments d ON e.department_id = d.dept_id LIMIT 10"
}'

# LEFT JOINæµ‹è¯•
test_api "LEFT JOINæŸ¥è¯¢" "POST" "/api/multi_table_query" \
'{
  "files": ["employees.csv", "departments.csv"],
  "sql": "SELECT e.name, e.department_id, d.dept_name FROM employees e LEFT JOIN departments d ON e.department_id = d.dept_id LIMIT 10"
}'

# RIGHT JOINæµ‹è¯•
test_api "RIGHT JOINæŸ¥è¯¢" "POST" "/api/multi_table_query" \
'{
  "files": ["employees.csv", "departments.csv"],
  "sql": "SELECT e.name, d.dept_name, d.budget FROM employees e RIGHT JOIN departments d ON e.department_id = d.dept_id LIMIT 10"
}'

# FULL OUTER JOINæµ‹è¯•
test_api "FULL OUTER JOINæŸ¥è¯¢" "POST" "/api/multi_table_query" \
'{
  "files": ["employees.csv", "departments.csv"],
  "sql": "SELECT e.name, d.dept_name FROM employees e FULL OUTER JOIN departments d ON e.department_id = d.dept_id LIMIT 15"
}'

# ä¸‰è¡¨JOINæµ‹è¯•
test_api "ä¸‰è¡¨JOINæŸ¥è¯¢" "POST" "/api/multi_table_query" \
'{
  "files": ["employees.csv", "departments.csv", "projects.csv"],
  "sql": "SELECT e.name, d.dept_name, p.project_name, p.status FROM employees e INNER JOIN departments d ON e.department_id = d.dept_id LEFT JOIN projects p ON d.dept_id = p.department_id LIMIT 20"
}'

# ==========================================
# ç¬¬å››éƒ¨åˆ†ï¼šå¤æ‚æŸ¥è¯¢å’Œè¾¹ç¼˜æƒ…å†µæµ‹è¯•
# ==========================================
echo ""
echo "ğŸ§  ç¬¬å››éƒ¨åˆ†ï¼šå¤æ‚æŸ¥è¯¢å’Œè¾¹ç¼˜æƒ…å†µæµ‹è¯•"
echo "=============================="

# å­æŸ¥è¯¢æµ‹è¯•
test_api "å­æŸ¥è¯¢æµ‹è¯•" "POST" "/api/execute_simple_sql" \
'{"sql": "SELECT name, salary FROM employees WHERE salary > (SELECT AVG(salary) FROM employees)", "filename": "employees.csv"}'

# çª—å£å‡½æ•°æµ‹è¯•
test_api "çª—å£å‡½æ•°æµ‹è¯•" "POST" "/api/execute_simple_sql" \
'{"sql": "SELECT name, salary, department_id, ROW_NUMBER() OVER (PARTITION BY department_id ORDER BY salary DESC) as rank_in_dept FROM employees", "filename": "employees.csv"}'

# CASE WHENæµ‹è¯•
test_api "CASE WHENæ¡ä»¶æµ‹è¯•" "POST" "/api/execute_simple_sql" \
'{"sql": "SELECT name, age, CASE WHEN age < 30 THEN '\''å¹´è½»'\'' WHEN age < 35 THEN '\''ä¸­å¹´'\'' ELSE '\''èµ„æ·±'\'' END as age_group FROM employees", "filename": "employees.csv"}'

# æ—¥æœŸå‡½æ•°æµ‹è¯•
test_api "æ—¥æœŸå‡½æ•°æµ‹è¯•" "POST" "/api/execute_simple_sql" \
'{"sql": "SELECT name, hire_date, EXTRACT(YEAR FROM CAST(hire_date AS DATE)) as hire_year FROM employees", "filename": "employees.csv"}'

# å­—ç¬¦ä¸²å‡½æ•°æµ‹è¯•
test_api "å­—ç¬¦ä¸²å‡½æ•°æµ‹è¯•" "POST" "/api/execute_simple_sql" \
'{"sql": "SELECT UPPER(name) as upper_name, LENGTH(name) as name_length, SUBSTR(name, 1, 1) as first_char FROM employees", "filename": "employees.csv"}'

# NULLå€¼å¤„ç†æµ‹è¯•
test_api "NULLå€¼å¤„ç†æµ‹è¯•" "POST" "/api/execute_simple_sql" \
'{"sql": "SELECT dept_name, COALESCE(manager_id, 0) as manager_id, budget FROM departments", "filename": "departments.csv"}'

# HAVINGå­å¥æµ‹è¯•
test_api "HAVINGå­å¥æµ‹è¯•" "POST" "/api/execute_simple_sql" \
'{"sql": "SELECT department_id, COUNT(*) as emp_count, AVG(salary) as avg_salary FROM employees GROUP BY department_id HAVING COUNT(*) > 1", "filename": "employees.csv"}'

# UNIONæµ‹è¯•ï¼ˆéœ€è¦åˆ›å»ºå…¼å®¹çš„è¡¨ç»“æ„ï¼‰
test_api "UNIONæŸ¥è¯¢æµ‹è¯•" "POST" "/api/execute_simple_sql" \
'{"sql": "SELECT name as person_name, '\''å‘˜å·¥'\'' as type FROM employees UNION SELECT dept_name as person_name, '\''éƒ¨é—¨'\'' as type FROM departments", "filename": "employees.csv"}'

# ==========================================
# ç¬¬äº”éƒ¨åˆ†ï¼šè¾¹ç¼˜æƒ…å†µå’Œé”™è¯¯å¤„ç†æµ‹è¯•
# ==========================================
echo ""
echo "âš ï¸  ç¬¬äº”éƒ¨åˆ†ï¼šè¾¹ç¼˜æƒ…å†µå’Œé”™è¯¯å¤„ç†æµ‹è¯•"
echo "==============================="

# ç©ºç»“æœæŸ¥è¯¢
test_api "ç©ºç»“æœæŸ¥è¯¢" "POST" "/api/execute_simple_sql" \
'{"sql": "SELECT * FROM employees WHERE age > 100", "filename": "employees.csv"}'

# è¯­æ³•é”™è¯¯æŸ¥è¯¢
test_api "SQLè¯­æ³•é”™è¯¯æµ‹è¯•" "POST" "/api/execute_simple_sql" \
'{"sql": "SELCT * FORM employees", "filename": "employees.csv"}'

# ä¸å­˜åœ¨çš„åˆ—
test_api "ä¸å­˜åœ¨çš„åˆ—æµ‹è¯•" "POST" "/api/execute_simple_sql" \
'{"sql": "SELECT non_existent_column FROM employees", "filename": "employees.csv"}'

# ä¸å­˜åœ¨çš„è¡¨
test_api "ä¸å­˜åœ¨çš„è¡¨æµ‹è¯•" "POST" "/api/execute_simple_sql" \
'{"sql": "SELECT * FROM non_existent_table", "filename": "employees.csv"}'

# ä¸å­˜åœ¨çš„æ–‡ä»¶
test_api "ä¸å­˜åœ¨çš„æ–‡ä»¶æµ‹è¯•" "POST" "/api/execute_simple_sql" \
'{"sql": "SELECT * FROM test", "filename": "non_existent_file.csv"}'

# å¤§æ•°æ®é‡æŸ¥è¯¢ï¼ˆæ— LIMITï¼‰
test_api "å¤§æ•°æ®é‡æŸ¥è¯¢æµ‹è¯•" "POST" "/api/execute_simple_sql" \
'{"sql": "SELECT * FROM employees", "filename": "employees.csv"}'

# å¤æ‚JOINæŸ¥è¯¢
test_api "å¤æ‚å¤šæ¡ä»¶JOIN" "POST" "/api/multi_table_query" \
'{
  "files": ["employees.csv", "departments.csv", "sales.csv"],
  "sql": "SELECT e.name, d.dept_name, s.amount FROM employees e LEFT JOIN departments d ON e.department_id = d.dept_id LEFT JOIN sales s ON e.emp_id = s.emp_id WHERE s.amount > 40000"
}'

# ==========================================
# ç¬¬å…­éƒ¨åˆ†ï¼šæ•°æ®åº“è¿æ¥æµ‹è¯•
# ==========================================
echo ""
echo "ğŸ—„ï¸  ç¬¬å…­éƒ¨åˆ†ï¼šæ•°æ®åº“è¿æ¥æµ‹è¯•"
echo "========================"

# æµ‹è¯•æ•°æ®åº“è¿æ¥ï¼ˆSQLiteç¤ºä¾‹ï¼‰
test_api "SQLiteæ•°æ®åº“è¿æ¥æµ‹è¯•" "POST" "/api/database_connections/test" \
'{
  "type": "sqlite",
  "database": ":memory:",
  "host": "",
  "port": 0,
  "username": "",
  "password": ""
}'

# æµ‹è¯•MySQLè¿æ¥ï¼ˆå‡è®¾æœ‰æœ¬åœ°MySQLï¼‰
test_api "MySQLæ•°æ®åº“è¿æ¥æµ‹è¯•" "POST" "/api/database_connections/test" \
'{
  "type": "mysql",
  "host": "localhost",
  "port": 3306,
  "database": "test",
  "username": "root",
  "password": "password"
}'

# è·å–æ•°æ®åº“è¿æ¥åˆ—è¡¨
test_api "è·å–æ•°æ®åº“è¿æ¥åˆ—è¡¨" "GET" "/api/database_connections" ""

# ==========================================
# ç¬¬ä¸ƒéƒ¨åˆ†ï¼šæ•°æ®å¯¼å‡ºæµ‹è¯•
# ==========================================
echo ""
echo "ğŸ“¤ ç¬¬ä¸ƒéƒ¨åˆ†ï¼šæ•°æ®å¯¼å‡ºæµ‹è¯•"
echo "====================="

# æµ‹è¯•Excelå¯¼å‡º
test_api "Excelå¯¼å‡ºæµ‹è¯•" "POST" "/api/download" \
'{
  "dataSources": [
    {"id": "employees", "type": "file", "path": "employees.csv"}
  ],
  "selectedColumns": ["name", "age", "salary"],
  "limit": 10
}'

# ==========================================
# ç¬¬å…«éƒ¨åˆ†ï¼šæ€§èƒ½å’Œå‹åŠ›æµ‹è¯•
# ==========================================
echo ""
echo "âš¡ ç¬¬å…«éƒ¨åˆ†ï¼šæ€§èƒ½å’Œå‹åŠ›æµ‹è¯•"
echo "======================"

# åˆ›å»ºå¤§æ•°æ®é›†è¿›è¡Œæµ‹è¯•
log_info "åˆ›å»ºå¤§æ•°æ®é›†æµ‹è¯•æ–‡ä»¶"
cat > large_dataset.csv << 'EOF'
id,name,value,category,date
EOF

# ç”Ÿæˆ1000è¡Œæµ‹è¯•æ•°æ®
for i in {1..1000}; do
    echo "$i,ç”¨æˆ·$i,$((RANDOM % 10000)),ç±»åˆ«$((i % 10)),2021-0$((i % 12 + 1))-01" >> large_dataset.csv
done

# ä¸Šä¼ å¤§æ•°æ®é›†
upload_result=$(curl -s -X POST -F "file=@large_dataset.csv" "$API_BASE/api/upload")
if echo "$upload_result" | grep -q "success"; then
    log_success "å¤§æ•°æ®é›†ä¸Šä¼ æˆåŠŸ"

    # æµ‹è¯•å¤§æ•°æ®é›†æŸ¥è¯¢
    test_api "å¤§æ•°æ®é›†èšåˆæŸ¥è¯¢" "POST" "/api/execute_simple_sql" \
    '{"sql": "SELECT category, COUNT(*) as count, AVG(value) as avg_value FROM large_dataset GROUP BY category ORDER BY count DESC", "filename": "large_dataset.csv"}'

    # æµ‹è¯•åˆ†é¡µæŸ¥è¯¢
    test_api "åˆ†é¡µæŸ¥è¯¢æµ‹è¯•" "POST" "/api/execute_simple_sql" \
    '{"sql": "SELECT * FROM large_dataset ORDER BY id LIMIT 50 OFFSET 100", "filename": "large_dataset.csv"}'
else
    log_error "å¤§æ•°æ®é›†ä¸Šä¼ å¤±è´¥"
fi

# ==========================================
# ç¬¬ä¹éƒ¨åˆ†ï¼šæ¸…ç†å’Œæ€»ç»“
# ==========================================
echo ""
echo "ğŸ§¹ ç¬¬ä¹éƒ¨åˆ†ï¼šæ¸…ç†å’Œæ€»ç»“"
echo "==================="

# æ¸…ç†æµ‹è¯•æ–‡ä»¶
log_info "æ¸…ç†æµ‹è¯•æ–‡ä»¶"
rm -f employees.csv departments.csv projects.csv sales.csv large_dataset.csv

# è·å–æœ€ç»ˆæ–‡ä»¶åˆ—è¡¨
final_files=$(curl -s "$API_BASE/api/list_files")
log_info "æœ€ç»ˆæ–‡ä»¶åˆ—è¡¨: $final_files"

echo ""
echo "ğŸ¯ å…¨åŠŸèƒ½æµ‹è¯•æ€»ç»“"
echo "================"
log_success "åŸºç¡€æŸ¥è¯¢åŠŸèƒ½æµ‹è¯•å®Œæˆ"
log_success "JOINæ“ä½œæµ‹è¯•å®Œæˆ"
log_success "å¤æ‚æŸ¥è¯¢æµ‹è¯•å®Œæˆ"
log_success "è¾¹ç¼˜æƒ…å†µæµ‹è¯•å®Œæˆ"
log_success "æ•°æ®åº“è¿æ¥æµ‹è¯•å®Œæˆ"
log_success "å¯¼å‡ºåŠŸèƒ½æµ‹è¯•å®Œæˆ"
log_success "æ€§èƒ½æµ‹è¯•å®Œæˆ"

echo ""
echo "ğŸ“‹ æµ‹è¯•è¦†ç›–çš„åŠŸèƒ½ï¼š"
echo "âœ… å•è¡¨æŸ¥è¯¢ï¼ˆSELECT, WHERE, ORDER BY, GROUP BYï¼‰"
echo "âœ… å¤šè¡¨JOINï¼ˆINNER, LEFT, RIGHT, FULL OUTERï¼‰"
echo "âœ… ä¸‰è¡¨åŠä»¥ä¸Šå¤æ‚JOIN"
echo "âœ… å­æŸ¥è¯¢å’Œçª—å£å‡½æ•°"
echo "âœ… èšåˆå‡½æ•°å’Œç»Ÿè®¡æŸ¥è¯¢"
echo "âœ… å­—ç¬¦ä¸²å’Œæ—¥æœŸå‡½æ•°"
echo "âœ… NULLå€¼å¤„ç†"
echo "âœ… UNIONæ“ä½œ"
echo "âœ… é”™è¯¯å¤„ç†å’Œè¾¹ç¼˜æƒ…å†µ"
echo "âœ… æ•°æ®åº“è¿æ¥ç®¡ç†"
echo "âœ… æ•°æ®å¯¼å‡ºåŠŸèƒ½"
echo "âœ… å¤§æ•°æ®é›†å¤„ç†"
echo "âœ… åˆ†é¡µæŸ¥è¯¢"

echo ""
echo "ğŸš€ DataQuery Pro å·²é€šè¿‡å…¨åŠŸèƒ½æµ‹è¯•ï¼"
