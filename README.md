# Interactive Data Query Platform

[![Version](https://img.shields.io/badge/version-2.1.0-blue.svg)](https://github.com/your-repo/interactive-data-query)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](./LICENSE)
[![Python](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/)
[![React](https://img.shields.io/badge/react-18.2+-blue.svg)](https://reactjs.org/)

[ä¸­æ–‡æ–‡æ¡£](./README_zh.md) | [Documentation](./docs/) | [Contributing](./docs/fix-summaries/CONTRIBUTING.md)

A powerful, modern web-based platform for interactive data analysis and multi-source data joining. Seamlessly query and analyze data from various sources including CSV files, Excel spreadsheets, and databases (MySQL, PostgreSQL) using the high-performance DuckDB engine.

## âœ¨ Core Features

- **ğŸ”— Multi-Source Data Joining**: Advanced JOIN operations across different data sources (files + databases)
- **ğŸ“Š Multiple Data Formats**: Support for CSV, Excel (.xlsx/.xls), JSON, Parquet, and PDF files
- **ğŸ—„ï¸ Database Integration**: Native support for MySQL, PostgreSQL, and SQLite with connection pooling
- **âš¡ High-Performance Engine**: Powered by DuckDB for lightning-fast analytical queries
- **ğŸ¨ Modern UI/UX**: Responsive interface built with React, Material-UI, and AG-Grid
- **ğŸ“ˆ Visual Query Builder**: Intuitive drag-and-drop interface for building complex queries
- **ğŸ”„ Smart Query Proxy**: Automatic request format conversion for seamless frontend-backend communication
- **ğŸ“¤ Export Capabilities**: Export results to Excel, CSV, JSON, and Parquet formats
- **ğŸ§ª Comprehensive Testing**: Full test suite with 80%+ coverage and automated testing
- **ğŸ³ Easy Deployment**: Multiple deployment options including Docker, Vercel, and self-hosted

## ğŸ› ï¸ Tech Stack

| Category          | Technology                               | Version    |
| ----------------- | ---------------------------------------- | ---------- |
| **Backend**       | FastAPI (Python)                        | Latest     |
| **Data Engine**   | DuckDB                                   | Latest     |
| **Data Processing** | Pandas, SQLAlchemy                     | Latest     |
| **Frontend**      | React with Vite                         | 18.2+      |
| **UI Framework**  | Material-UI (MUI), AG-Grid              | 5.14+      |
| **Database**      | MySQL, PostgreSQL, SQLite               | Multiple   |
| **Deployment**    | Docker, Vercel, Cloudflare Pages        | -          |
| **Testing**       | Comprehensive test suite                 | 80%+ coverage |

## ğŸ“ Project Structure

```
interactive-data-query/
â”œâ”€â”€ ğŸ“„ README.md                    # Project documentation (English)
â”œâ”€â”€ ğŸ“„ README_zh.md                 # Project documentation (Chinese)
â”œâ”€â”€ ğŸ“„ PROJECT_STRUCTURE.md         # Detailed project structure guide
â”œâ”€â”€ ğŸ“„ LICENSE                      # MIT License
â”œâ”€â”€ ğŸ”§ run-tests.sh                 # Quick test runner
â”œâ”€â”€ ğŸ³ docker-compose.yml           # Docker deployment configuration
â”œâ”€â”€ ğŸ“„ vercel.json                  # Vercel deployment configuration
â”‚
â”œâ”€â”€ ğŸ”§ api/                         # Backend API (FastAPI)
â”‚   â”œâ”€â”€ ğŸ“„ main.py                  # Application entry point
â”‚   â”œâ”€â”€ ğŸ“„ requirements.txt         # Python dependencies
â”‚   â”œâ”€â”€ ğŸ³ Dockerfile               # Backend Docker configuration
â”‚   â”œâ”€â”€ ğŸ“ core/                    # Core business logic
â”‚   â”‚   â”œâ”€â”€ duckdb_engine.py        # DuckDB integration
â”‚   â”‚   â”œâ”€â”€ resource_manager.py     # Resource management
â”‚   â”‚   â””â”€â”€ database_manager.py     # Database connections
â”‚   â”œâ”€â”€ ğŸ“ models/                  # Data models
â”‚   â”‚   â”œâ”€â”€ query_models.py         # Query-related models
â”‚   â”‚   â””â”€â”€ database_models.py      # Database models
â”‚   â”œâ”€â”€ ğŸ“ routers/                 # API endpoints
â”‚   â”‚   â”œâ”€â”€ data_sources.py         # Data source management
â”‚   â”‚   â”œâ”€â”€ query.py                # Query execution
â”‚   â”‚   â”œâ”€â”€ query_proxy.py          # Smart query proxy with format conversion
â”‚   â”‚   â”œâ”€â”€ export.py               # Data export
â”‚   â”‚   â””â”€â”€ enhanced_data_sources.py # Enhanced data source features
â”‚   â””â”€â”€ ğŸ“ data/                    # Uploaded data files
â”‚
â”œâ”€â”€ ğŸ¨ frontend/                    # Frontend application (React)
â”‚   â”œâ”€â”€ ğŸ“„ package.json             # Node.js dependencies
â”‚   â”œâ”€â”€ ğŸ“„ vite.config.js           # Vite configuration
â”‚   â”œâ”€â”€ ğŸ“„ index.html               # HTML template
â”‚   â”œâ”€â”€ ğŸ³ Dockerfile               # Frontend Docker configuration
â”‚   â”œâ”€â”€ ğŸ“„ .env.example             # Environment variables template
â”‚   â””â”€â”€ ğŸ“ src/                     # Source code
â”‚       â”œâ”€â”€ ğŸ“„ App.jsx              # Main application component
â”‚       â”œâ”€â”€ ğŸ“„ main.jsx             # Application entry point
â”‚       â”œâ”€â”€ ğŸ“ components/          # React components
â”‚       â”‚   â”œâ”€â”€ DataGrid.jsx        # Data display grid
â”‚       â”‚   â”œâ”€â”€ DataSourceManager/  # Data source management UI
â”‚       â”‚   â”œâ”€â”€ QueryBuilder/       # Visual query builder
â”‚       â”‚   â””â”€â”€ ExportManager/      # Export functionality UI
â”‚       â”œâ”€â”€ ğŸ“ services/            # API client services
â”‚       â”‚   â””â”€â”€ apiClient.js        # HTTP client configuration
â”‚       â””â”€â”€ ğŸ“ assets/              # Static assets
â”‚
â”œâ”€â”€ ğŸ§ª tests/                       # Comprehensive test suite
â”‚   â”œâ”€â”€ ğŸ“„ README.md                # Testing documentation
â”‚   â”œâ”€â”€ ğŸ”§ run-all-tests.sh         # Aggregated test runner
â”‚   â”œâ”€â”€ ğŸ“ unit/                    # Unit tests (future expansion)
â”‚   â”œâ”€â”€ ğŸ“ integration/             # Integration tests (future expansion)
â”‚   â”œâ”€â”€ ğŸ“ e2e/                     # End-to-end tests (future expansion)
â”‚   â””â”€â”€ ğŸ“ scripts/                 # Test scripts
â”‚       â”œâ”€â”€ test-all-functions.sh   # Core functionality tests
â”‚       â”œâ”€â”€ test-api-functions.sh   # API endpoint tests
â”‚       â”œâ”€â”€ test-datasource-fixes.sh # Data source tests
â”‚       â”œâ”€â”€ test-query-fix.sh       # Query functionality tests
â”‚       â”œâ”€â”€ test-ui-fixes.sh        # UI functionality tests
â”‚       â””â”€â”€ [8 more test scripts]   # Additional specialized tests
â”‚
â”œâ”€â”€ ğŸ“š docs/                        # Documentation
â”‚   â”œâ”€â”€ ğŸ“„ README.md                # Documentation index
â”‚   â”œâ”€â”€ ğŸ“ fix-summaries/           # Development and fix documentation
â”‚   â”‚   â”œâ”€â”€ CHANGELOG.md            # Version history
â”‚   â”‚   â”œâ”€â”€ CONTRIBUTING.md         # Contribution guidelines
â”‚   â”‚   â”œâ”€â”€ DEPLOYMENT_REPORT.md    # Deployment verification
â”‚   â”‚   â”œâ”€â”€ FINAL_IMPLEMENTATION_SUMMARY.md # Implementation summary
â”‚   â”‚   â””â”€â”€ [7 more documentation files]
â”‚   â””â”€â”€ ğŸ“ test-reports/            # Test reports (future expansion)
â”‚
â”œâ”€â”€ ğŸ”§ scripts/                     # Utility scripts
â”‚   â”œâ”€â”€ ğŸ“ deployment/              # Deployment scripts
â”‚   â”œâ”€â”€ ğŸ“ development/             # Development utilities
â”‚   â”œâ”€â”€ ğŸ“ docker/                  # Docker-related scripts
â”‚   â””â”€â”€ ğŸ“ testing/                 # Testing utilities
â”‚
â”œâ”€â”€ ğŸ—ƒï¸ config/                      # Configuration files
â”‚   â”œâ”€â”€ ğŸ“ deployment/              # Deployment configurations
â”‚   â””â”€â”€ ğŸ“ docker/                  # Docker configurations
â”‚
â”œâ”€â”€ ğŸ“¦ archive/                     # Archived files
â”‚   â”œâ”€â”€ ğŸ“ deprecated/              # Deprecated code
â”‚   â””â”€â”€ ğŸ“ old-tests/               # Legacy test files
â”‚
â””â”€â”€ ğŸ“ temp_files/                  # Temporary files (auto-generated)
```

> **Note**: This structure reflects the recent project reorganization for better maintainability and testing coverage.

## ğŸš€ Quick Start

### Prerequisites

- [Node.js](https://nodejs.org/) (v18 or later)
- [Python](https://www.python.org/) (v3.9 or later)
- [Docker](https://www.docker.com/) (optional, for containerized setup)

### Method 1: Docker Deployment (Recommended)

The fastest and most reliable way to get started:

```bash
# Clone the repository
git clone <repository-url>
cd interactive-data-query

# ğŸš€ ä¸€é”®å¯åŠ¨ (æ¨è)
./docker-start.sh

# æˆ–æ‰‹åŠ¨å¯åŠ¨
docker-compose -f docker-compose.full.yml up --build -d
```

> **ğŸ“ Note**: ä½¿ç”¨ `docker-compose.full.yml` é…ç½®æ–‡ä»¶å®ç°å‰åç«¯ç»Ÿä¸€Dockeréƒ¨ç½²ã€‚

**Access the application:**
- ğŸŒ å‰ç«¯ç•Œé¢: http://localhost:3000
- ğŸ“¡ åç«¯API: http://localhost:8000
- ğŸ“š APIæ–‡æ¡£: http://localhost:8000/docs
- ğŸ” å¥åº·æ£€æŸ¥: http://localhost:8000/health
- ğŸ”„ æŸ¥è¯¢ä»£ç†: http://localhost:8000/api/query_proxy (è‡ªåŠ¨æ ¼å¼è½¬æ¢)
- ğŸ“¤ ä¸‹è½½ä»£ç†: http://localhost:8000/api/download_proxy (è‡ªåŠ¨å¯¼å‡ºæ ¼å¼è½¬æ¢)

**Common Docker commands:**
```bash
# æŸ¥çœ‹æœåŠ¡çŠ¶æ€
docker-compose -f docker-compose.full.yml ps

# æŸ¥çœ‹å®æ—¶æ—¥å¿—
docker-compose -f docker-compose.full.yml logs -f

# åœæ­¢æœåŠ¡
docker-compose -f docker-compose.full.yml down

# é‡æ–°æ„å»ºå¹¶å¯åŠ¨
docker-compose -f docker-compose.full.yml up --build -d

# é‡å¯æœåŠ¡
docker-compose -f docker-compose.full.yml restart
```

### Method 2: Local Development Setup

For development and customization:

```bash
# Clone the repository
git clone <repository-url>
cd interactive-data-query

# Start backend
cd api
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
uvicorn main:app --reload --host 0.0.0.0 --port 8000

# In a new terminal, start frontend
cd frontend
npm install
npm run dev
```

**Access the application:**
- Frontend: http://localhost:5173
- Backend API: http://localhost:8000

### Method 3: One-Click Scripts

Use the provided convenience scripts:

```bash
# For local development (installs dependencies automatically)
./start-local.sh

# For Docker deployment with optimized settings
./start-fixed.sh
```

## ğŸ§ª Testing

This project includes a comprehensive testing framework with 80%+ test coverage.

### Run All Tests

```bash
# Quick test runner (recommended)
./run-tests.sh

# Comprehensive test suite
./tests/run-all-tests.sh
```

### Test Categories

- **Core Functionality Tests**: Essential features and API endpoints
- **Data Source Tests**: File upload, database connections, data preview
- **Query Tests**: JOIN operations, SQL execution, result validation
- **UI Tests**: Frontend components, user interactions, responsive design
- **Integration Tests**: End-to-end workflows and data processing

### Test Results

Current test status:
- **Total Test Scripts**: 10
- **Passing Tests**: 8 (80% success rate)
- **Test Coverage**: Core functionality, API endpoints, UI components

## ğŸš€ Deployment

### Cloud Platforms

#### Vercel (Recommended for Frontend)
```bash
# Connect your GitHub repository to Vercel
# The vercel.json configuration handles automatic deployment
```

#### Cloudflare Pages
```bash
# Build settings:
# Build command: npm run build (in frontend directory)
# Output directory: frontend/dist
# Deploy backend separately as Cloudflare Worker
```

#### Railway/Render (Full-Stack)
```bash
# Deploy both frontend and backend together
# Use the provided Docker configuration
```

### Self-Hosted Deployment

#### Docker Production Setup
```bash
# Production deployment
docker-compose -f config/docker/docker-compose.yml up -d

# With custom environment
cp frontend/.env.example frontend/.env.production
# Edit environment variables as needed
docker-compose -f config/docker/docker-compose.yml up --build -d

# Check service status
docker-compose -f config/docker/docker-compose.yml ps

# View service logs
docker-compose -f config/docker/docker-compose.yml logs -f
```

#### Traditional Server Setup
```bash
# Backend (Python/FastAPI)
cd api
pip install -r requirements.txt
gunicorn main:app --workers 4 --worker-class uvicorn.workers.UvicornWorker

# Frontend (React/Vite)
cd frontend
npm install
npm run build
# Serve the dist/ directory with nginx or apache
```

### Environment Configuration

Create environment files:
```bash
# Frontend environment
cp frontend/.env.example frontend/.env.production

# Backend environment (if needed)
export DATABASE_URL="your-database-connection-string"
export CORS_ORIGINS="https://your-frontend-domain.com"
```

## ğŸ’¡ Usage Examples

### Basic Data Analysis Workflow

1. **Upload Data Sources**
   - Upload CSV/Excel files or connect to databases
   - Preview data and verify schema detection

2. **Build Queries**
   - Use the visual query builder to create JOIN operations
   - Preview SQL queries before execution

3. **Analyze Results**
   - View results in the interactive data grid
   - Sort, filter, and explore your data

4. **Export Results**
   - Export to Excel, CSV, JSON, or Parquet formats
   - Download for further analysis

### Advanced Features

- **Multi-table JOINs**: Combine data from 3+ sources
- **Database Integration**: Query live production databases
- **Performance Optimization**: Leverage DuckDB's analytical engine
- **Smart Query Proxy**: Automatic format conversion between frontend and backend
- **Responsive Design**: Works on desktop, tablet, and mobile

### Query Proxy System

The platform includes an intelligent query proxy (`/api/query_proxy`) that automatically converts between different request formats:

- **Automatic Data Source Conversion**: Converts frontend data source objects to backend-compatible format
- **JOIN Format Translation**: Transforms `{left_on, right_on, how}` to `{join_type, conditions}` format
- **Backward Compatibility**: Supports mixed format requests for seamless upgrades
- **Error Prevention**: Eliminates 422 validation errors from format mismatches

**Usage**: Frontend automatically uses the proxy endpoints for all query and export operations, ensuring seamless communication regardless of data format differences.

### Export System

The platform includes intelligent export capabilities with automatic format handling:

- **Download Proxy**: `/api/download_proxy` endpoint automatically converts request formats for Excel/CSV exports
- **Column Name Handling**: Multi-table JOINs use A_1, A_2, B_1, B_2 aliases to avoid Chinese column name conflicts
- **Format Support**: Exports maintain the same column naming convention as query results
- **Error Prevention**: Eliminates 422 validation errors from export format mismatches

**Export Features**:
- Excel (.xlsx) and CSV export with proper encoding
- Preserves A_1, B_1 alias format for multi-table results
- Automatic request format conversion
- Support for large dataset exports

## ğŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guide](./docs/fix-summaries/CONTRIBUTING.md) for details.

### Development Setup

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Run the test suite: `./run-tests.sh`
5. Submit a pull request

### Reporting Issues

- Use GitHub Issues for bug reports and feature requests
- Include detailed reproduction steps
- Provide system information and error logs

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](./LICENSE) file for details.

## ğŸ™ Acknowledgments

- **DuckDB Team** - For the amazing analytical database engine
- **FastAPI** - For the modern Python web framework
- **React Team** - For the excellent frontend framework
- **Material-UI** - For the beautiful UI components
- **AG-Grid** - For the powerful data grid component

## ğŸ“ Support

- **Documentation**: [./docs/](./docs/)
- **Issues**: [GitHub Issues](https://github.com/your-repo/interactive-data-query/issues)
- **Discussions**: [GitHub Discussions](https://github.com/your-repo/interactive-data-query/discussions)

---

**Made with â¤ï¸ for data analysts and developers**

*Star â­ this repository if you find it helpful!*
