# API Core ç›®å½•é‡æ„ - è®¾è®¡æ–‡æ¡£

> **ç‰ˆæœ¬**: 2.5 (æœ€ç»ˆç‰ˆ - å®Œå–„è¦†ç›–èŒƒå›´ä¸é…ç½®åŒ–)  
> **åˆ›å»ºæ—¶é—´**: 2026-01-15  
> **çŠ¶æ€**: ğŸ“ è®¾è®¡å®Œæˆ

---

## ğŸ“ æ¶æ„è®¾è®¡

### åˆ†å±‚ç›®å½•ç»“æ„

```
api/core/
â”œâ”€â”€ __init__.py              # ä»…ç‰ˆæœ¬ä¿¡æ¯ï¼Œä¸åš Re-export
â”œâ”€â”€ foundation/              # Layer 0: é›¶ä¾èµ–åŸºç¡€å·¥å…·
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ encoding_utils.py
â”‚   â”œâ”€â”€ crypto_utils.py
â”‚   â””â”€â”€ timezone_utils.py
â”œâ”€â”€ common/                  # Layer 1: ä»…ä¾èµ– foundation
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config_manager.py
â”‚   â”œâ”€â”€ validators.py
â”‚   â”œâ”€â”€ exceptions.py
â”‚   â”œâ”€â”€ error_codes.py
â”‚   â”œâ”€â”€ cache_manager.py
â”‚   â”œâ”€â”€ utils.py
â”‚   â””â”€â”€ enhanced_error_handler.py
â”œâ”€â”€ database/                # Layer 2: å¯ä¾èµ– L0, L1
â”‚   â””â”€â”€ ...
â”œâ”€â”€ security/                # Layer 2: å¯ä¾èµ– L0, L1
â”‚   â””â”€â”€ ...
â”œâ”€â”€ data/                    # Layer 2: å¯ä¾èµ– L0, L1
â”‚   â””â”€â”€ ...
â””â”€â”€ services/                # Layer 3: å¯ä¾èµ–æ‰€æœ‰ä½å±‚
    â””â”€â”€ ...
```

---

## ğŸ“œ Google Python Style Guide è‡ªåŠ¨åŒ–éªŒè¯

### Ruff é…ç½®ï¼ˆæ ¸å¿ƒï¼‰

**æ–‡ä»¶**: `api/pyproject.toml` æˆ– `api/ruff.toml`

```toml
[tool.ruff]
target-version = "py311"
line-length = 100
src = ["api"]

[tool.ruff.lint]
select = [
    "E",      # pycodestyle errors
    "F",      # pyflakes
    "I",      # isort
    "D",      # pydocstyle (docstrings)
    "ANN",    # flake8-annotations
    "LOG",    # flake8-logging-format
    "TID252", # ç¦æ­¢ç›¸å¯¹å¯¼å…¥
]
ignore = [
    "D100",   # Missing docstring in public module
    "D104",   # Missing docstring in public package
    "ANN101", # Missing type annotation for self
    "ANN102", # Missing type annotation for cls
]

[tool.ruff.lint.pydocstyle]
convention = "google"

[tool.ruff.lint.flake8-tidy-imports]
ban-relative-imports = "all"  # âœ… æ ¸å¿ƒï¼šç¦æ­¢æ‰€æœ‰ç›¸å¯¹å¯¼å…¥
```

> [!IMPORTANT]
> **ä½œç”¨åŸŸç¡®è®¤**ï¼š`ruff check api/` å‘½ä»¤ä¼šé€’å½’æ£€æŸ¥ `api/core/**/*.py`ã€`api/routers/**/*.py` ç­‰æ‰€æœ‰å­ç›®å½•ã€‚è¿ç§»å®Œæˆååº”è¿è¡Œ `ruff check api/ --statistics` ç¡®è®¤è¦†ç›–å…¨éƒ¨æ–‡ä»¶ã€‚

### CI é…ç½®

**æ–‡ä»¶**: `.github/workflows/lint.yml`

```yaml
name: Lint

on: [push, pull_request]

jobs:
  ruff:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: astral-sh/ruff-action@v1
        with:
          args: "check api/"
          
  import-check:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      - name: Install dependencies
        run: pip install -r api/requirements.txt
      - name: Check layer constraints
        run: |
          cd api && python -m scripts.check_layer_constraints
      - name: Test all imports
        run: |
          cd api && python -m scripts.test_all_imports
```

---

## ğŸ”§ å…³é”®è®¾è®¡

### 1. crypto_utils.pyï¼ˆçº¿ç¨‹å®‰å…¨ç‰ˆï¼‰

**æ–‡ä»¶**: `api/core/foundation/crypto_utils.py`

```python
"""Cryptographic utilities for password and secret management.

This module provides low-level encryption primitives. It has ZERO dependencies
on other core submodules to avoid circular imports.

Thread Safety:
    Uses threading.Lock to ensure safe initialization in multi-threaded
    environments (e.g., Gunicorn with multiple workers starting simultaneously).
"""

from __future__ import annotations

import base64
import logging
import os
import threading
from pathlib import Path
from typing import Any

from cryptography.fernet import Fernet, InvalidToken

logger = logging.getLogger(__name__)

_SECRET_KEY_FILENAME = "secret.key"
_DEFAULT_PASSWORD_KEYS = ("password", "secret", "token", "api_key")


class CryptoManager:
    """Thread-safe manager for encryption/decryption operations.
    
    Attributes:
        _fernet: Lazily initialized Fernet instance.
        _lock: Threading lock for safe initialization.
    """
    
    def __init__(self) -> None:
        self._fernet: Fernet | None = None
        self._lock = threading.Lock()
    
    def _get_secret_key_path(self) -> Path:
        """Returns the path to the secret key file.
        
        The path is determined by:
        1. CONFIG_DIR environment variable (if set)
        2. Default: <project_root>/config/secret.key
        
        Raises:
            PermissionError: If the key directory is not writable.
        """
        config_dir = os.getenv(
            "CONFIG_DIR",
            str(Path(__file__).parent.parent.parent.parent / "config")
        )
        return Path(config_dir) / _SECRET_KEY_FILENAME
    
    def _get_fernet(self) -> Fernet:
        """Returns the Fernet instance, creating one if necessary.
        
        Thread-safe: Uses double-checked locking pattern.
        
        Returns:
            A Fernet instance for encryption/decryption.
            
        Raises:
            PermissionError: If unable to write new key file.
            OSError: If unable to read existing key file.
        """
        if self._fernet is not None:
            return self._fernet
            
        with self._lock:
            # Double-check after acquiring lock
            if self._fernet is not None:
                return self._fernet
                
            key_path = self._get_secret_key_path()
            
            if key_path.exists():
                key = key_path.read_bytes()
                logger.debug("Loaded encryption key from: %s", key_path)
            else:
                key = Fernet.generate_key()
                try:
                    key_path.parent.mkdir(parents=True, exist_ok=True)
                    key_path.write_bytes(key)
                    logger.info("Generated new encryption key: %s", key_path)
                except PermissionError:
                    logger.warning(
                        "Cannot write key to %s (read-only filesystem?). "
                        "Using ephemeral key - encrypted data won't persist.",
                        key_path,
                    )
                    
            self._fernet = Fernet(key)
            return self._fernet


# Module-level singleton
_crypto_manager = CryptoManager()


def encrypt_string(plaintext: str) -> str:
    """Encrypts a plaintext string using Fernet symmetric encryption.
    
    Args:
        plaintext: The string to encrypt. If empty, returns as-is.
        
    Returns:
        Base64-encoded encrypted string.
    """
    if not plaintext:
        return plaintext
    encrypted = _crypto_manager._get_fernet().encrypt(plaintext.encode())
    return base64.urlsafe_b64encode(encrypted).decode()


def decrypt_string(ciphertext: str) -> str:
    """Decrypts an encrypted string.
    
    Args:
        ciphertext: Base64-encoded encrypted string. If empty, returns as-is.
        
    Returns:
        The decrypted plaintext. If decryption fails, returns the original
        input (assumes it may have been stored in plaintext).
    """
    if not ciphertext:
        return ciphertext
    try:
        encrypted = base64.urlsafe_b64decode(ciphertext.encode())
        return _crypto_manager._get_fernet().decrypt(encrypted).decode()
    except (InvalidToken, TypeError, ValueError) as e:
        logger.warning("Decryption failed, returning original: %s", e)
        return ciphertext


def decrypt_config_passwords(
    config: dict[str, Any],
    keys: tuple[str, ...] | None = None,
) -> dict[str, Any]:
    """Decrypts password fields in a configuration dictionary.
    
    Args:
        config: Configuration dictionary that may contain encrypted values.
        keys: Field names to decrypt. Defaults to common password field names.
        
    Returns:
        A copy of the config with specified fields decrypted.
    """
    keys = keys or _DEFAULT_PASSWORD_KEYS
    result = config.copy()
    for key in keys:
        if key in result and result[key]:
            result[key] = decrypt_string(result[key])
    return result
```

---

### 2. AST å¯¼å…¥æ”¹å†™è„šæœ¬ï¼ˆå¤„ç†ç›¸å¯¹å¯¼å…¥ï¼‰

**æ–‡ä»¶**: `api/scripts/rewrite_imports.py`

```python
#!/usr/bin/env python3
"""Rewrites imports from old paths to new paths using AST.

Handles BOTH absolute and relative imports:
- Converts `from core.xxx import` to `from core.subpackage.xxx import`
- Converts `from .xxx import` to absolute imports

Usage:
    python api/scripts/rewrite_imports.py --dry-run  # Preview
    python api/scripts/rewrite_imports.py            # Apply
"""

from __future__ import annotations

import argparse
import ast
import json
import sys
from pathlib import Path

MAPPING_FILE = Path(__file__).parent / "import_mapping.json"
API_DIR = Path(__file__).parent.parent
CORE_DIR = API_DIR / "core"


def load_mapping() -> dict[str, str]:
    """Loads the import path mapping from JSON file."""
    with open(MAPPING_FILE, encoding="utf-8") as f:
        return json.load(f)


def resolve_relative_to_absolute(
    filepath: Path,
    level: int,
    module: str | None,
) -> str | None:
    """Resolves a relative import to its absolute module path.
    
    Args:
        filepath: Path to the file containing the import.
        level: Number of dots in relative import (1 for ., 2 for ..).
        module: The module name after the dots.
        
    Returns:
        Absolute module path, or None if resolution fails.
    """
    try:
        rel_path = filepath.relative_to(API_DIR)
        parts = list(rel_path.parts[:-1])  # Remove filename
        
        if level > len(parts):
            return None
            
        base_parts = parts[: len(parts) - level + 1]
        
        if module:
            return ".".join(base_parts + module.split("."))
        return ".".join(base_parts)
    except ValueError:
        return None


class ImportRewriter(ast.NodeTransformer):
    """AST transformer that rewrites imports."""
    
    def __init__(
        self,
        filepath: Path,
        mapping: dict[str, str],
    ) -> None:
        self.filepath = filepath
        self.mapping = mapping
        self.changes: list[tuple[int, str, str]] = []
    
    def visit_ImportFrom(self, node: ast.ImportFrom) -> ast.ImportFrom:
        """Transforms ImportFrom nodes."""
        original_module = node.module or ""
        
        # Handle relative imports
        if node.level > 0:
            resolved = resolve_relative_to_absolute(
                self.filepath, node.level, node.module
            )
            if resolved and resolved in self.mapping:
                new_module = self.mapping[resolved]
                self.changes.append((
                    node.lineno,
                    f"from {'.' * node.level}{original_module}",
                    f"from {new_module}",
                ))
                node.level = 0
                node.module = new_module
        # Handle absolute imports
        elif original_module in self.mapping:
            new_module = self.mapping[original_module]
            self.changes.append((
                node.lineno,
                f"from {original_module}",
                f"from {new_module}",
            ))
            node.module = new_module
            
        return node


def rewrite_file(
    filepath: Path,
    mapping: dict[str, str],
    dry_run: bool,
) -> int:
    """Rewrites imports in a single file using AST.
    
    Args:
        filepath: Path to the Python file.
        mapping: Old path -> new path mapping.
        dry_run: If True, only print changes without modifying.
        
    Returns:
        Number of changes made.
    """
    try:
        content = filepath.read_text(encoding="utf-8")
        tree = ast.parse(content)
    except (SyntaxError, UnicodeDecodeError) as e:
        print(f"[SKIP] {filepath}: {e}")
        return 0
    
    rewriter = ImportRewriter(filepath, mapping)
    new_tree = rewriter.visit(tree)
    
    if not rewriter.changes:
        return 0
    
    if dry_run:
        for lineno, old, new in rewriter.changes:
            print(f"[DRY-RUN] {filepath}:{lineno}: {old} -> {new}")
    else:
        # Regenerate source from AST
        try:
            import astor
            new_content = astor.to_source(new_tree)
        except ImportError:
            # Fallback: simple regex replacement
            new_content = content
            for _, old, new in rewriter.changes:
                new_content = new_content.replace(old, new)
        
        filepath.write_text(new_content, encoding="utf-8")
        for lineno, old, new in rewriter.changes:
            print(f"[UPDATED] {filepath}:{lineno}: {old} -> {new}")
    
    return len(rewriter.changes)


def main() -> int:
    """Main entry point."""
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument("--dry-run", action="store_true", help="Preview only")
    args = parser.parse_args()
    
    mapping = load_mapping()
    total = 0
    
    for py_file in API_DIR.rglob("*.py"):
        if "__pycache__" in str(py_file):
            continue
        total += rewrite_file(py_file, mapping, args.dry_run)
    
    print(f"\nTotal: {total} changes")
    return 0


if __name__ == "__main__":
    sys.exit(main())
```

---

### 3. ç›¸å¯¹å¯¼å…¥æ£€æµ‹è„šæœ¬ï¼ˆç‹¬ç«‹éªŒè¯ï¼‰

**æ–‡ä»¶**: `api/scripts/check_relative_imports.py`

```python
#!/usr/bin/env python3
"""Detects and reports any relative imports in core modules.

This is a standalone check to enforce absolute imports per Google Style Guide.
Run as CI gate to prevent accidental relative imports.

Usage:
    python api/scripts/check_relative_imports.py
"""

from __future__ import annotations

import ast
import sys
from pathlib import Path

API_DIR = Path(__file__).parent.parent


def check_file(filepath: Path) -> list[str]:
    """Checks a file for relative imports.
    
    Returns:
        List of violation messages.
    """
    violations: list[str] = []
    
    try:
        content = filepath.read_text(encoding="utf-8")
        tree = ast.parse(content)
    except (SyntaxError, UnicodeDecodeError):
        return []
    
    lines = content.splitlines()
    
    for node in ast.walk(tree):
        if isinstance(node, ast.ImportFrom) and node.level > 0:
            line = lines[node.lineno - 1].strip() if node.lineno <= len(lines) else ""
            violations.append(
                f"{filepath.relative_to(API_DIR)}:{node.lineno}: "
                f"Relative import found: '{line}'"
            )
    
    return violations


def main() -> int:
    """Main entry point."""
    all_violations: list[str] = []
    
    # Check ALL api/ subdirectories (core, routers, tests, scripts, tools, etc.)
    for py_file in API_DIR.rglob("*.py"):
        if "__pycache__" in str(py_file):
            continue
        all_violations.extend(check_file(py_file))
    
    if all_violations:
        print("âŒ Relative imports found (violates Google Style Guide):")
        for v in all_violations:
            print(f"  - {v}")
        print(f"\nTotal: {len(all_violations)} violations")
        print("Fix: Convert to absolute imports, e.g., 'from core.xxx import'")
        return 1
    
    print("âœ… No relative imports found")
    return 0


if __name__ == "__main__":
    sys.exit(main())
```

---

### 4. å…¨é‡å¯¼å…¥æµ‹è¯•ï¼ˆå¸¦å¯é…ç½®è·³è¿‡åˆ—è¡¨ï¼‰

**æ–‡ä»¶**: `api/scripts/test_all_imports.py`

```python
#!/usr/bin/env python3
"""Tests all .py files can be imported without errors.

Some modules with external dependencies or side effects are skipped.
Skip list can be extended via SKIP_MODULES environment variable.

Usage:
    python api/scripts/test_all_imports.py
    
    # Add extra modules to skip:
    SKIP_MODULES="core/database/database_manager.py,core/external/..." python api/scripts/test_all_imports.py
"""

from __future__ import annotations

import importlib.util
import os
import sys
from pathlib import Path

API_DIR = Path(__file__).parent.parent
sys.path.insert(0, str(API_DIR))

# Pattern-based skip (always applied)
SKIP_PATTERNS = [
    "test_",
    "conftest",
    "__pycache__",
]

# Default modules to skip (require external resources)
# Add paths relative to api/, e.g., "core/database/database_manager.py"
DEFAULT_SKIP_MODULES: list[str] = [
    # Example: "core/database/external_conn.py"  # Needs live DB
]


def get_skip_modules() -> set[str]:
    """Returns the combined skip modules from default and environment variable."""
    modules = set(DEFAULT_SKIP_MODULES)
    
    # Allow adding extra modules via environment variable
    env_skips = os.getenv("SKIP_MODULES", "")
    if env_skips:
        modules.update(m.strip() for m in env_skips.split(",") if m.strip())
    
    return modules


def should_skip(filepath: Path, skip_modules: set[str]) -> bool:
    """Determines if a file should be skipped."""
    path_str = str(filepath)
    
    for pattern in SKIP_PATTERNS:
        if pattern in path_str:
            return True
    
    rel_path = str(filepath.relative_to(API_DIR))
    return rel_path in skip_modules


def main() -> int:
    """Main entry point."""
    errors: list[str] = []
    skipped = 0
    tested = 0
    skip_modules = get_skip_modules()
    
    if skip_modules:
        print(f"Skip modules: {', '.join(skip_modules)}")
    
    for py_file in API_DIR.rglob("*.py"):
        if should_skip(py_file, skip_modules):
            skipped += 1
            continue
        
        try:
            spec = importlib.util.spec_from_file_location("mod", py_file)
            if spec and spec.loader:
                module = importlib.util.module_from_spec(spec)
                spec.loader.exec_module(module)
            tested += 1
        except Exception as e:
            errors.append(f"{py_file.relative_to(API_DIR)}: {e}")
    
    print(f"Tested: {tested}, Skipped: {skipped}")
    
    if errors:
        print(f"\nâŒ Import errors ({len(errors)}):")
        for err in errors:
            print(f"  - {err}")
        return 1
    
    print("âœ… All imports successful")
    return 0


if __name__ == "__main__":
    sys.exit(main())
```

---

## ğŸ¤– è¿è¡Œç¯å¢ƒé…ç½®

### Makefileï¼ˆæ¨èï¼‰

**æ–‡ä»¶**: `api/Makefile`

```makefile
.PHONY: lint test import-check layer-check

# ç¡®ä¿ PYTHONPATH åŒ…å« api/
export PYTHONPATH := $(shell pwd)

lint:
	ruff check .

lint-fix:
	ruff check --fix .

test:
	pytest tests/ -v

import-check:
	python -m scripts.test_all_imports

layer-check:
	python -m scripts.check_layer_constraints

relative-check:
	python -m scripts.check_relative_imports

# å®Œæ•´éªŒè¯æµç¨‹
verify: lint relative-check layer-check import-check test
	@echo "âœ… All checks passed"
```

### sys.path ç¡®ä¿è„šæœ¬

**æ–‡ä»¶**: `api/scripts/__init__.py`

```python
"""Ensures api/ is in sys.path when running scripts.

Usage:
    cd api && python -m scripts.check_layer_constraints
"""

import sys
from pathlib import Path

API_DIR = Path(__file__).parent.parent

if str(API_DIR) not in sys.path:
    sys.path.insert(0, str(API_DIR))
```

---

## ğŸ§ª éªŒæ”¶æ£€æŸ¥æ¸…å•

### è‡ªåŠ¨åŒ–éªŒè¯ï¼ˆCI å¿…é¡»é€šè¿‡ï¼‰

| æ£€æŸ¥é¡¹ | å‘½ä»¤ | è¯´æ˜ |
|--------|------|------|
| Ruff é£æ ¼æ£€æŸ¥ | `ruff check api/` | Docstring/ç±»å‹æ³¨è§£/æ—¥å¿—æ ¼å¼ |
| ç›¸å¯¹å¯¼å…¥æ£€æµ‹ | `python -m scripts.check_relative_imports` | ç¦æ­¢ç›¸å¯¹å¯¼å…¥ |
| åˆ†å±‚çº¦æŸæ£€æµ‹ | `python -m scripts.check_layer_constraints` | å±‚çº§ä¾èµ–è§„åˆ™ |
| å…¨é‡å¯¼å…¥æµ‹è¯• | `python -m scripts.test_all_imports` | æ—  ImportError |
| å•å…ƒæµ‹è¯• | `pytest api/tests/` | åŠŸèƒ½å›å½’ |

### æ‰€æœ‰ 27 ä¸ªæ–‡ä»¶çš„é£æ ¼è¡¥å…¨

| ä»»åŠ¡ | æ–‡ä»¶èŒƒå›´ |
|------|---------|
| æ·»åŠ  Google Docstring | æ‰€æœ‰å…¬å…±å‡½æ•°/ç±» |
| æ·»åŠ ç±»å‹æ³¨è§£ | æ‰€æœ‰å…¬å…±å‡½æ•°å‚æ•°å’Œè¿”å›å€¼ |
| å¼‚å¸¸å…·ä½“åŒ– | æ›¿æ¢ `except Exception` ä¸ºå…·ä½“ç±»å‹ |
| æ—¥å¿—æ ¼å¼ | æ›¿æ¢ f-string ä¸º `%` å ä½ç¬¦ |

---

## ğŸ“¦ `__init__.py` å¤„ç†è§„èŒƒ

### core/__init__.pyï¼ˆè¿ç§»åä¿ç•™ï¼‰

è¿ç§»å®Œæˆåï¼Œ`api/core/__init__.py` **ä»…ä¿ç•™ç‰ˆæœ¬ä¿¡æ¯ï¼Œä¸å¯¼å‡ºä»»ä½•å­æ¨¡å—**ï¼š

```python
"""Core package for the DuckDB Query API.

This package provides database connection management, configuration,
security utilities, and data processing services.

Usage:
    from core.database.duckdb_engine import get_db_connection
    from core.common.config_manager import config_manager
"""

__version__ = "2.0.0"
```

> [!WARNING]
> **ä¸è¦æ·»åŠ  Re-export**ï¼šå¦‚ `from core.common.config_manager import config_manager`ã€‚
> è¿™ä¼šå¯¼è‡´ lint/å¯¼å…¥æµ‹è¯•è¯¯ä»¥ä¸ºæ—§è·¯å¾„ä»å¯ç”¨ã€‚

### å­åŒ… `__init__.py`

æ¯ä¸ªå­åŒ…ï¼ˆfoundation/common/database/security/data/servicesï¼‰çš„ `__init__.py` ä¿æŒç©ºæˆ–ä»…å« docstringï¼š

```python
"""Common utilities and configuration management."""
```

---

## ğŸ”„ è¿ç§»åå¯¼å…¥æ”¹å†™

> [!IMPORTANT]
> **å¯¼å…¥æ”¹å†™éœ€åœ¨è¿ç§»å®Œæˆåå†è¿è¡Œä¸€æ¬¡**ï¼Œä»¥æ•è·è¿ç§»è¿‡ç¨‹ä¸­å¯èƒ½æ–°å¢çš„ç›¸å¯¹å¯¼å…¥æˆ–è·¯å¾„é—æ¼ã€‚

```bash
# è¿ç§»å‰ï¼šé¢„è§ˆ
python api/scripts/rewrite_imports.py --dry-run

# è¿ç§»åï¼šæœ€ç»ˆæ”¹å†™
python api/scripts/rewrite_imports.py

# éªŒè¯æ— é—æ¼
python api/scripts/check_relative_imports.py
grep -rn "from core\." api/ --include="*.py" | grep -v "__pycache__"
```

## ğŸ“Š å¯¼å…¥æ˜ å°„

**æ–‡ä»¶**: `api/scripts/import_mapping.json`

```json
{
  "core.timezone_utils": "core.foundation.timezone_utils",
  "core.config_manager": "core.common.config_manager",
  "core.validators": "core.common.validators",
  "core.exceptions": "core.common.exceptions",
  "core.error_codes": "core.common.error_codes",
  "core.cache_manager": "core.common.cache_manager",
  "core.utils": "core.common.utils",
  "core.enhanced_error_handler": "core.common.enhanced_error_handler",
  "core.duckdb_engine": "core.database.duckdb_engine",
  "core.duckdb_pool": "core.database.duckdb_pool",
  "core.database_manager": "core.database.database_manager",
  "core.connection_registry": "core.database.connection_registry",
  "core.metadata_manager": "core.database.metadata_manager",
  "core.table_metadata_cache": "core.database.table_metadata_cache",
  "core.encryption": "core.security.encryption",
  "core.security": "core.security.security",
  "core.sql_injection_protection": "core.security.sql_injection_protection",
  "core.rate_limiter": "core.security.rate_limiter",
  "core.file_datasource_manager": "core.data.file_datasource_manager",
  "core.excel_import_manager": "core.data.excel_import_manager",
  "core.file_utils": "core.data.file_utils",
  "core.task_manager": "core.services.task_manager",
  "core.task_utils": "core.services.task_utils",
  "core.visual_query_generator": "core.services.visual_query_generator",
  "core.cleanup_scheduler": "core.services.cleanup_scheduler",
  "core.resource_manager": "core.services.resource_manager"
}
```
