#!/usr/bin/env python3
"""
æµ‹è¯•å¢å¼ºåŠŸèƒ½çš„è„šæœ¬
éªŒè¯æ–°æ·»åŠ çš„å¤šæ•°æ®æºå…³è”åˆ†æå¹³å°åŠŸèƒ½
"""

import sys
import os
import pandas as pd
import json
import tempfile
from pathlib import Path

# æ·»åŠ APIç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), 'api'))

from models.query_models import (
    DataSourceType,
    DatabaseConnection,
    ConnectionTestRequest,
    QueryRequest,
    DataSource,
    Join,
    JoinType,
    JoinCondition,
    ExportRequest,
    ExportFormat
)
from core.database_manager import db_manager
from core.duckdb_engine import (
    get_db_connection,
    register_dataframe,
    build_join_query,
    detect_column_conflicts,
    generate_column_aliases
)


def test_file_formats():
    """æµ‹è¯•æ–°æ–‡ä»¶æ ¼å¼æ”¯æŒ"""
    print("ğŸ§ª æµ‹è¯•æ–‡ä»¶æ ¼å¼æ”¯æŒ...")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    test_data = {
        'id': [1, 2, 3, 4, 5],
        'name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],
        'age': [25, 30, 35, 28, 32],
        'city': ['New York', 'London', 'Tokyo', 'Paris', 'Sydney']
    }
    df = pd.DataFrame(test_data)
    
    with tempfile.TemporaryDirectory() as temp_dir:
        temp_path = Path(temp_dir)
        
        # æµ‹è¯•CSV
        csv_file = temp_path / "test.csv"
        df.to_csv(csv_file, index=False)
        print(f"âœ… CSVæ–‡ä»¶åˆ›å»ºæˆåŠŸ: {csv_file}")
        
        # æµ‹è¯•Excel
        excel_file = temp_path / "test.xlsx"
        df.to_excel(excel_file, index=False)
        print(f"âœ… Excelæ–‡ä»¶åˆ›å»ºæˆåŠŸ: {excel_file}")
        
        # æµ‹è¯•JSON
        json_file = temp_path / "test.json"
        df.to_json(json_file, orient='records', indent=2)
        print(f"âœ… JSONæ–‡ä»¶åˆ›å»ºæˆåŠŸ: {json_file}")
        
        # æµ‹è¯•Parquet
        try:
            parquet_file = temp_path / "test.parquet"
            df.to_parquet(parquet_file, index=False)
            print(f"âœ… Parquetæ–‡ä»¶åˆ›å»ºæˆåŠŸ: {parquet_file}")
        except ImportError:
            print("âš ï¸  Parquetæ”¯æŒéœ€è¦pyarrowåº“")
    
    print("âœ… æ–‡ä»¶æ ¼å¼æµ‹è¯•å®Œæˆ\n")


def test_database_manager():
    """æµ‹è¯•æ•°æ®åº“è¿æ¥ç®¡ç†å™¨"""
    print("ğŸ§ª æµ‹è¯•æ•°æ®åº“è¿æ¥ç®¡ç†å™¨...")
    
    # æµ‹è¯•SQLiteè¿æ¥
    sqlite_connection = DatabaseConnection(
        id="test_sqlite",
        type=DataSourceType.SQLITE,
        params={"database": ":memory:"},
        name="æµ‹è¯•SQLiteè¿æ¥"
    )
    
    # æµ‹è¯•è¿æ¥
    test_request = ConnectionTestRequest(
        type=DataSourceType.SQLITE,
        params={"database": ":memory:"}
    )
    
    result = db_manager.test_connection(test_request)
    if result.success:
        print(f"âœ… SQLiteè¿æ¥æµ‹è¯•æˆåŠŸ: {result.message}")
        print(f"   å»¶è¿Ÿ: {result.latency_ms:.2f}ms")
    else:
        print(f"âŒ SQLiteè¿æ¥æµ‹è¯•å¤±è´¥: {result.message}")
    
    # æ·»åŠ è¿æ¥
    success = db_manager.add_connection(sqlite_connection)
    if success:
        print("âœ… SQLiteè¿æ¥æ·»åŠ æˆåŠŸ")
    else:
        print("âŒ SQLiteè¿æ¥æ·»åŠ å¤±è´¥")
    
    # åˆ—å‡ºè¿æ¥
    connections = db_manager.list_connections()
    print(f"âœ… å½“å‰è¿æ¥æ•°é‡: {len(connections)}")
    
    print("âœ… æ•°æ®åº“è¿æ¥ç®¡ç†å™¨æµ‹è¯•å®Œæˆ\n")


def test_enhanced_join():
    """æµ‹è¯•å¢å¼ºçš„JOINåŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•å¢å¼ºJOINåŠŸèƒ½...")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    users_data = pd.DataFrame({
        'user_id': [1, 2, 3, 4],
        'name': ['Alice', 'Bob', 'Charlie', 'David'],
        'email': ['alice@example.com', 'bob@example.com', 'charlie@example.com', 'david@example.com']
    })
    
    orders_data = pd.DataFrame({
        'order_id': [101, 102, 103, 104, 105],
        'user_id': [1, 2, 1, 3, 2],
        'product': ['Laptop', 'Mouse', 'Keyboard', 'Monitor', 'Headphones'],
        'amount': [1200, 25, 75, 300, 150]
    })
    
    products_data = pd.DataFrame({
        'product': ['Laptop', 'Mouse', 'Keyboard', 'Monitor', 'Headphones'],
        'category': ['Electronics', 'Accessories', 'Accessories', 'Electronics', 'Accessories'],
        'price': [1200, 25, 75, 300, 150]
    })
    
    # æ³¨å†Œåˆ°DuckDB
    con = get_db_connection()
    register_dataframe("users", users_data, con)
    register_dataframe("orders", orders_data, con)
    register_dataframe("products", products_data, con)
    
    print("âœ… æµ‹è¯•æ•°æ®æ³¨å†Œåˆ°DuckDB")
    
    # åˆ›å»ºæ•°æ®æº
    users_source = DataSource(
        id="users",
        type=DataSourceType.CSV,
        params={},
        columns=users_data.columns.tolist()
    )
    
    orders_source = DataSource(
        id="orders", 
        type=DataSourceType.CSV,
        params={},
        columns=orders_data.columns.tolist()
    )
    
    products_source = DataSource(
        id="products",
        type=DataSourceType.CSV, 
        params={},
        columns=products_data.columns.tolist()
    )
    
    # æµ‹è¯•åˆ—å†²çªæ£€æµ‹
    conflicts = detect_column_conflicts([users_source, orders_source, products_source])
    print(f"âœ… æ£€æµ‹åˆ°åˆ—å†²çª: {conflicts}")
    
    # ç”Ÿæˆåˆ—åˆ«å
    aliases = generate_column_aliases([users_source, orders_source, products_source])
    print(f"âœ… ç”Ÿæˆåˆ—åˆ«å: {json.dumps(aliases, indent=2)}")
    
    # åˆ›å»ºå¤æ‚JOINæŸ¥è¯¢
    joins = [
        Join(
            left_source_id="users",
            right_source_id="orders", 
            join_type=JoinType.LEFT,
            conditions=[
                JoinCondition(left_column="user_id", right_column="user_id", operator="=")
            ]
        ),
        Join(
            left_source_id="orders",
            right_source_id="products",
            join_type=JoinType.INNER,
            conditions=[
                JoinCondition(left_column="product", right_column="product", operator="=")
            ]
        )
    ]
    
    query_request = QueryRequest(
        sources=[users_source, orders_source, products_source],
        joins=joins,
        limit=100
    )
    
    # æ„å»ºæŸ¥è¯¢
    sql_query = build_join_query(query_request)
    print(f"âœ… ç”Ÿæˆçš„SQLæŸ¥è¯¢:\n{sql_query}")
    
    # æ‰§è¡ŒæŸ¥è¯¢
    try:
        from core.duckdb_engine import execute_query
        result = execute_query(sql_query, con)
        print(f"âœ… æŸ¥è¯¢æ‰§è¡ŒæˆåŠŸï¼Œè¿”å› {len(result)} è¡Œæ•°æ®")
        print("å‰5è¡Œæ•°æ®:")
        print(result.head().to_string())
    except Exception as e:
        print(f"âŒ æŸ¥è¯¢æ‰§è¡Œå¤±è´¥: {str(e)}")
    
    print("âœ… å¢å¼ºJOINåŠŸèƒ½æµ‹è¯•å®Œæˆ\n")


def test_export_functionality():
    """æµ‹è¯•å¯¼å‡ºåŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•å¯¼å‡ºåŠŸèƒ½...")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    test_data = pd.DataFrame({
        'id': range(1, 101),
        'name': [f'User_{i}' for i in range(1, 101)],
        'value': [i * 10 for i in range(1, 101)]
    })
    
    with tempfile.TemporaryDirectory() as temp_dir:
        temp_path = Path(temp_dir)
        
        # æµ‹è¯•CSVå¯¼å‡º
        csv_file = temp_path / "export_test.csv"
        test_data.to_csv(csv_file, index=False)
        print(f"âœ… CSVå¯¼å‡ºæµ‹è¯•: {csv_file}")
        
        # æµ‹è¯•Excelå¯¼å‡º
        excel_file = temp_path / "export_test.xlsx"
        test_data.to_excel(excel_file, index=False)
        print(f"âœ… Excelå¯¼å‡ºæµ‹è¯•: {excel_file}")
        
        # æµ‹è¯•JSONå¯¼å‡º
        json_file = temp_path / "export_test.json"
        test_data.to_json(json_file, orient='records', indent=2)
        print(f"âœ… JSONå¯¼å‡ºæµ‹è¯•: {json_file}")
        
        # æµ‹è¯•Parquetå¯¼å‡º
        try:
            parquet_file = temp_path / "export_test.parquet"
            test_data.to_parquet(parquet_file, index=False)
            print(f"âœ… Parquetå¯¼å‡ºæµ‹è¯•: {parquet_file}")
        except ImportError:
            print("âš ï¸  Parquetå¯¼å‡ºéœ€è¦pyarrowåº“")
    
    print("âœ… å¯¼å‡ºåŠŸèƒ½æµ‹è¯•å®Œæˆ\n")


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æµ‹è¯•å¢å¼ºåŠŸèƒ½...\n")
    
    try:
        test_file_formats()
        test_database_manager()
        test_enhanced_join()
        test_export_functionality()
        
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆ!")
        print("\nğŸ“‹ æµ‹è¯•æ€»ç»“:")
        print("âœ… æ–‡ä»¶æ ¼å¼æ”¯æŒ (CSV, Excel, JSON, Parquet)")
        print("âœ… æ•°æ®åº“è¿æ¥ç®¡ç†")
        print("âœ… å¢å¼ºJOINåŠŸèƒ½")
        print("âœ… å¯¼å‡ºåŠŸèƒ½")
        print("\nğŸ”§ ä¸‹ä¸€æ­¥:")
        print("1. å¯åŠ¨åç«¯æœåŠ¡: cd api && uvicorn main:app --reload")
        print("2. å¯åŠ¨å‰ç«¯æœåŠ¡: cd frontend && npm run dev")
        print("3. è®¿é—® http://localhost:5173 æµ‹è¯•å®Œæ•´åŠŸèƒ½")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())
